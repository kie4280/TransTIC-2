model: "tic_promptmodel_first2"
training_data_path: /disk2/dataset/
training_dataset: [ "BSD400", "DIV2K", "Flickr2K", "flicker", "WaterlooED"] # ["BSD400", "DIV2K", "Flickr2K", "WaterlooED", "flicker"]
testing_data_path: /disk2/dataset/test/
testing_dataset: ["Urban100"]
epochs: 400
learning_rate: 1.e-4
num_workers: 0
quality_level: 1 # {1,2,3,4}
lmbda: 0.0018 # {0.0018, 0.0035, 0.0067, 0.013}
batch_size: 8
test_batch_size: 1
aux_learning_rate: 1.e-3
patch_size: 256
cuda: True
gpu_id: 0
save: True
clip_max_norm: 1.0
root: "/disk2/finalproject_team22_record/"
name: "NAME"
exp_name: "full_TransTIC"
seed: 42
checkpoint: '/disk2/finalproject_team22/TransTIC/TIC_weight/1/base_codec_1.pth.tar'
LOCATION: "prepend"
DEEP: True
NUM_TOKENS: 16
INITIATION: "random"
PROJECT: -1
DROPOUT: 0.
TRANSFER_TYPE: "prompt"
ARCHITECT: "both"
VPT_lmbda: 0.0018
WINDOW: "same"
HYPERPRIOR: False
RETURN_ATTENTION: False
MODEL_DECODER: False
MASK_DOWNSAMPLE: 2
DECODER_BLOCK: [1, 2, 3, 4]
TEST: True
